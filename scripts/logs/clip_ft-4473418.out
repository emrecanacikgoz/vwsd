=======================
Loading Anaconda Module...
"data":    {'debug': True, 'batch_size': 4, 'num_workers': 5, 'train_dir': '/datasets/SemEval/semeval-2023-task-1-V-WSD-train-v1/train_v1', 'trial_dir': '/datasets/SemEval/semeval-2023-task-1-V-WSD-train-v1/trial_v1'}
"model":   {'name': 'CLIPFinetune'}
"output":  clip_ft.out
"seed":    12345
"trainer": {'accelerator': 'gpu', 'devices': 1, 'max_epochs': 15, 'precision': 16, 'gradient_clip_val': 1.0, 'val_check_interval': 1.0, 'resume_from_checkpoint': None, 'accumulate_grad_batches': 1, 'num_sanity_val_steps': 0}
/scratch/users/oince22/vwsd/scripts
self.debug: True
Config: "data":    {'debug': True, 'batch_size': 4, 'num_workers': 5, 'train_dir': '/datasets/SemEval/semeval-2023-task-1-V-WSD-train-v1/train_v1', 'trial_dir': '/datasets/SemEval/semeval-2023-task-1-V-WSD-train-v1/trial_v1'}
"model":   {'name': 'CLIPFinetune'}
"output":  /scratch/users/oince22/vwsd/scripts/clip_ft.out
"seed":    12345
"trainer": {'accelerator': 'gpu', 'devices': 1, 'max_epochs': 15, 'precision': 16, 'gradient_clip_val': 1.0, 'val_check_interval': 1.0, 'resume_from_checkpoint': None, 'accumulate_grad_batches': 1, 'num_sanity_val_steps': 0}
/scratch/users/oince22/vwsd/scripts
self.debug: True
/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /scratch/users/oince22/vwsd/scripts/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/10 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/10 [00:00<?, ?it/s] /kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/PIL/Image.py:3035: DecompressionBombWarning: Image size (89550550 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.
  warnings.warn(
B, N, C, H, W: (4, 10, 3, 224, 224)
Error executing job with overrides: []
Traceback (most recent call last):
  File "/scratch/users/oince22/vwsd/scripts/clip_ft_pred.py", line 39, in main
    results = trainer.fit(experiment, datamodule=train_dm)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 582, in fit
    call._call_and_handle_interrupt(
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 624, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1061, in _run
    results = self._run_stage()
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1140, in _run_stage
    self._run_train()
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1163, in _run_train
    self.fit_loop.run()
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 214, in advance
    batch_output = self.batch_loop.run(kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(optimizers, kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 200, in advance
    result = self._run_optimization(kwargs, self._optimizers[self.optim_progress.optimizer_position])
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 247, in _run_optimization
    self._optimizer_step(optimizer, opt_idx, kwargs.get("batch_idx", 0), closure)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 357, in _optimizer_step
    self.trainer._call_lightning_module_hook(
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1305, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/core/module.py", line 1661, in optimizer_step
    optimizer.step(closure=optimizer_closure)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/core/optimizer.py", line 169, in step
    step_output = self._strategy.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 234, in optimizer_step
    return self.precision_plugin.optimizer_step(
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/native_amp.py", line 85, in optimizer_step
    closure_result = closure()
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 147, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 133, in closure
    step_output = self._step_fn()
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 406, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *kwargs.values())
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1443, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 378, in training_step
    return self.model.training_step(*args, **kwargs)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/vwsd-0.0.1-py3.10.egg/vwsd/experiment.py", line 42, in training_step
    loss = F.cross_entropy(prob, labels)
  File "/kuacc/users/oince22/.conda/envs/vwsd/lib/python3.10/site-packages/torch/nn/functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
ValueError: Expected input batch_size (4) to match target batch_size (1).

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
Epoch 0:   0%|          | 0/10 [00:12<?, ?it/s]
